_Overview_

Nothing ruins the thrill of buying a brand new car more quickly than seeing your new insurance bill. The sting’s even more painful when you know you’re a good driver. It doesn’t seem fair that you have to pay so much if you’ve been cautious on the road for years.

Porto Seguro, one of Brazil’s largest auto and homeowner insurance companies, completely agrees. Inaccuracies in car insurance company’s claim predictions raise the cost of insurance for good drivers and reduce the price for bad ones.

In this competition, you’re challenged to build a model that predicts the probability that a driver will initiate an auto insurance claim in the next year. While Porto Seguro has used machine learning for the past 20 years, they’re looking to Kaggle’s machine learning community to explore new, more powerful methods. A more accurate prediction will allow them to further tailor their prices, and hopefully make auto insurance coverage more accessible to more drivers.


_Data Description_

In this competition, you will predict the probability that an auto insurance policy holder files a claim.

In the train and test data, features that belong to similar groupings are tagged as such in the feature names (e.g., 'ind', 'reg', 'car', 'calc'). In addition, feature names include the postfix 'bin' to indicate binary features and 'cat' to indicate categorical features. Features without these designations are either continuous or ordinal. Values of -1 indicate that the feature was missing from the observation. The target columns signifies whether or not a claim was filed for that policy holder.
File descriptions

-train.csv contains the training data, where each row corresponds to a policy holder, and the target columns signifies that a claim was filed.

_Metrics_
1) matthews_corrcoef
2) roc_auc_score

_Task for exam_ (30 points)
1) Take a look on the data. Build some main statistics, plots
2) Feature engineering. Transform feature space using commom methods (e.g. ohe-hot encoding, PCA, drop uncorrelated features etc.). Show сreativity!
3) Balance dataset
4) Build ML models (3 is minimum) and compare them with each other.
5) Extra points for cross validation (+5)
6) Extra points for correct stacking (+15)

